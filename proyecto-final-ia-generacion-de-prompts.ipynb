{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a758ef-0ab4-4302-98ab-a8acca5b8eef",
   "metadata": {},
   "source": [
    "# Proyecto Final: \n",
    "# Generación automatizada de reportes con IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b00bfe-52bd-4f6d-999d-43ecf549c495",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33380d-6c61-467a-b280-5007df7147c7",
   "metadata": {},
   "source": [
    "### Nombre del proyecto:\n",
    "#### Generación automatizada de reportes con IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d30da-c3e9-4c0a-ad7b-005ce91727f5",
   "metadata": {},
   "source": [
    "### Presentación del problema a abordar:\n",
    "En el ámbito de la administración de sistemas y monitoreo IT, herramientas como **Zabbix** generan una gran cantidad de datos sobre disponibilidad, rendimiento y alertas. Aunque estos datos son esenciales, el proceso de convertirlos en reportes significativos para gerentes y stakeholders suele ser tedioso y consume tiempo, ya que requiere:\n",
    "\n",
    " - Extraer métricas relevantes de los sistemas.\n",
    "\n",
    " - Analizar tendencias y comportamientos en los datos.\n",
    "\n",
    " - Presentar resultados de manera clara y profesional.\n",
    "\n",
    "Este problema es particularmente relevante porque los reportes son fundamentales para tomar decisiones estratégicas, medir acuerdos de nivel de servicio (SLAs) y comunicar resultados de manera efectiva. Sin embargo, los equipos técnicos pueden perder un tiempo valioso en tareas repetitivas en lugar de enfocarse en actividades críticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7a696-7c2a-4824-abc1-b0bfcfccae78",
   "metadata": {},
   "source": [
    "### Desarrollo de la propuesta de solución:\n",
    "La solución propuesta consiste en desarrollar un sistema automatizado que utilice **modelos de IA** para generar reportes narrativos y también gráficos basados en datos extraídos de Zabbix. Este sistema tendrá dos componentes principales:\n",
    "\n",
    "**Texto a texto**:\n",
    "\n",
    "1. Usar prompts que transformen métricas y datos de Zabbix en un análisis narrativo.\n",
    "\n",
    "2. Por ejemplo, convertir una tabla con tiempos de disponibilidad e indisponibilidad de un cierto servicio en un resumen como:\n",
    "   - \"El servicio X tuvo una disponibilidad del 99.87% esta semana, cumpliendo con el SLA acordado. Hubo una interrupción de 15 minutos el día miércoles, causada por XY razón.\"\n",
    "\n",
    "\n",
    "**Texto a imagen**:\n",
    "\n",
    "1. Generar gráficos y diagramas (disponibilidad semanal, tiempos de indisponibilidad, etc.) basados en las métricas, que complementen el análisis narrativo.\n",
    "\n",
    "2. Por ejemplo: gráficos de barras para comparar la disponibilidad entre servicios o líneas de tiempo para visualizar tendencias. En caso de no quedar satisfecho con las generaciones de imágenes sobre estos puntos, nuestra contingencia será generar imágenes indicadoras a modo de resumen o pantallazo general de como fue el comportamiento de disponibilidad de los servicios monitoreados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce47eea-e8b2-4af9-b022-f795d3c29b3f",
   "metadata": {},
   "source": [
    "### Justificación de la viabilidad del proyecto:\n",
    "Este proyecto es técnicamente viable debido a:\n",
    "\n",
    "1. Acceso a herramientas: Se utilizará la API de OpenAI para implementar los modelos de IA necesarios.\n",
    "\n",
    "2. Procesamiento eficiente: Los datos provenientes de Zabbix ya están procesados en un formato amigable para la IA, además, al menos para esta segunda pre-entrega, partimos de una entrada de datos estática en el código.\n",
    "\n",
    "3. Control de costos: Los prompts se diseñaron para ser breves y optimizados, minimizando por ese lado el gasto de tokens al generar resúmenes y gráficos, no obstante, en algunos escenarios no se acudió al modelo de openai más barato, ya que se requiere de una inteligencia superior para lograr  análisis más complejos.  Así y todo, los costos siguen siendo minimos, ya que la ejecución del script es puntual, en principio es semanal. Además todas las respuestas cuentan con un limitador de tokens para evitar cualquier problema de desborde y topear los costos por respuesta como medida preventiva.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf308a2-0e93-4063-82cc-836c7f8f7405",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "### Objetivo general:\n",
    " - Automatizar la creación de resúmenes narrativos y gráficos representativos a partir de datos de disponibilidad y SLA.\n",
    "\n",
    "### Objetivos específicos:\n",
    "\n",
    " - Generar resúmenes narrativos claros y útiles a partir de datos procesados de Zabbix.\n",
    " - Crear gráficos conceptuales que visualicen de forma intuitiva el desempeño semanal.\n",
    " - Demostrar la efectividad de los modelos de IA en la generación automatizada de reportes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4c0ea-e611-40af-8079-3177f07c9f0b",
   "metadata": {},
   "source": [
    "## Metodología\n",
    "**Preparación de los datos (previo a este desarrollo):**\n",
    "\n",
    " - Extraer los datos de Zabbix usando su API\n",
    " - Procesar y formatear los datos en JSON, csv o excel (en caso de ser necesario)\n",
    "\n",
    "\n",
    "**Lectura de los datos:**\n",
    " - Lectura y procesamiento de los datos de Zabbix desde un archivo json, csv o excel\n",
    "\n",
    "\n",
    "**Generación del resumen narrativo:**\n",
    "\n",
    " - Crear prompts optimizados que alimenten el modelo de texto a texto (GPT).\n",
    " - Evaluar y ajustar los resultados generados para garantizar claridad y precisión.\n",
    "\n",
    "**Creación de gráficos visuales:**\n",
    "\n",
    " - Usar un modelo de texto a imagen para generar gráficos conceptuales basados en un score calculado por servicio.\n",
    "\n",
    "**Pruebas y ajustes:**\n",
    "\n",
    " - Validar los resultados con datos reales para garantizar que sean útiles y comprensibles.\n",
    " - Optimizar prompts para mejorar la relación costo-beneficio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7d6b5-c408-4306-bf10-05e80fbc9cd3",
   "metadata": {},
   "source": [
    "## Herramientas y tecnologías\n",
    "\n",
    "**Librerías:**\n",
    "\n",
    " - **openai (0.28)** para interacción con modelos de IA. Se fijó la versión 0.28 para este curso/proyecto\n",
    " - **json (last version)** para trabajar con datos estructudos en este formato\n",
    " - **pandas (last version)** para facilitar el manejo de los datos en csv y excel\n",
    " - **dotenv (last version)** para cargar variables de entorno\n",
    " - **os (last version)** para lectura de parámetros de un archivo, en este caso para leer el parámetro que almacena la apikey\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "**Técnicas de prompting:**\n",
    "\n",
    " - **One-shot prompting:** Para garantizar que el modelo produzca respuestas claras y específicas en situaciones donde el formato esperado es crítico (como el score).\n",
    " - **A few-shot prompting** Para alinear el resultado con la estructura propuesta, para ello brindamos ejemplos de como pretendemos que sea el formato de salida. Utilizamos esta técnica para definir el contexto (system role)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71bb4d1-866c-47cf-88dd-1252139ebe21",
   "metadata": {},
   "source": [
    "## Implementación\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a869e5b-1543-4f89-b3dc-a74e7ae11f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librería de openai para manejo de la IA\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bceb147-1565-47cd-b8f4-73ba1e48cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos otras librerías requeridas para uso del script\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271b17bf-3799-439c-a7e6-47df308e5139",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Definición de funciones a utilizar en el proyecto\n",
    "\n",
    "def configure_openai_api():\n",
    "    \"\"\"\n",
    "    Configura la API de OpenAI con la API-Key de las variables de entorno.\n",
    "    \"\"\"\n",
    "    # Cargar variables de entorno desde un archivo .env (load_dotenv de python-dotenv)\n",
    "    load_dotenv()\n",
    "\n",
    "    # Obtener la API key desde las variables de entorno\n",
    "    apikey = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not apikey:\n",
    "        raise ValueError(\"API key no encontrada. Asegurarse de que OPENAI_API_KEY esté configurado en las variables de entorno.\")    \n",
    "    return apikey\n",
    "\n",
    "def load_json(data_str):\n",
    "    \"\"\"\n",
    "    Carga un JSON a partir de un string.\n",
    "    \n",
    "    Args:\n",
    "        data_str (str): Un JSON en formato string.\n",
    "    \n",
    "    Returns:\n",
    "        dict: JSON parseado como un diccionario.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(data_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al cargar el JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_json_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Carga un JSON a partir de un archivo.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Ruta hacia el archivo JSON.\n",
    "    \n",
    "    Returns:\n",
    "        dict: JSON parseado como un diccionario.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error al cargar el archivo JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_csv_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Carga datos de un archivo CSV y devuelve un DataFrame de pandas.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Ruta hacia el archivo CSV.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame que contiene los datos del CSV, o None si ocurrió un error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        data = df.to_dict(orient=\"records\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró el archivo {file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: El archivo {file_path} está vacío o no es un CSV valido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado al cargar el CSV: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_excel_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Carga datos de un archivo Excel y devuelve un DataFrame de pandas.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Ruta hacia el archivo Excel.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame que contiene los datos de Excel, o None si ocurrió un error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        data = df.to_dict(orient=\"records\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró el archivo {file_path}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}. Por favor, asegurarse de que el archivo es un archivo Excel válido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado al cargar el Excel: {e}\")\n",
    "    return None\n",
    "\n",
    "def load_data(file_path, file_type):\n",
    "    \"\"\"\n",
    "    Carga los datos de entrada de un archivo según su tipo.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Ruta del archivo de entrada.\n",
    "        file_type (str): Tipo de archivo ('json', 'csv', 'excel').\n",
    "        \n",
    "    Returns:\n",
    "        dict: Datos parseados en formato diccionario.\n",
    "    \"\"\"\n",
    "    \n",
    "    if file_type == \"json\":\n",
    "        return load_json_from_file(file_path)\n",
    "    elif file_type == \"csv\":\n",
    "        return load_csv_from_file(file_path)\n",
    "    elif file_type == \"excel\":\n",
    "        return load_excel_from_file(file_path)\n",
    "    else:\n",
    "        print(f\"Error: Tipo de archivo no soportado '{file_type}'.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24d501a-dfb9-4049-98b3-dafb1040ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la api-key de variable de entorno\n",
    "apikey = configure_openai_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecce580e-7ca7-4036-b3ef-1b56322c08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos la api-key con la cual vamos a interactuar con la api de openai\n",
    "openai.api_key = apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6631074c-7df8-43ba-9d26-079174fb0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de entrada en data_in\n",
    "#data_in = load_json_from_file(\"./input_data_example1.json\")\n",
    "#data_in = load_data(\"./input_data_example1.json\", \"json\")\n",
    "#data_in = load_data(\"./input_data_example1.csv\", \"csv\")\n",
    "data_in = load_data(\"./input_data_example1.xlsx\", \"excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0527d04-f0a7-4bf5-8694-23e0924e0124",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'service_name': 'Servidor Web', 'availability': 99.87, 'downtime/total_minutes': 15, 'downtime/events/0/date': '2024-11-27', 'downtime/events/0/duration_minutes': 15.0, 'downtime/events/0/cause': 'Fallo de red', 'sla_target': 99.9, 'alerts': 3, 'observations': 'Cumplió con el SLA a pesar de una pequeña interrupción.'}, {'service_name': 'Servidor Backend', 'availability': 100.0, 'downtime/total_minutes': 0, 'downtime/events/0/date': nan, 'downtime/events/0/duration_minutes': nan, 'downtime/events/0/cause': nan, 'sla_target': 99.9, 'alerts': 0, 'observations': nan}, {'service_name': 'Base de Datos', 'availability': 99.95, 'downtime/total_minutes': 5, 'downtime/events/0/date': '2024-11-28', 'downtime/events/0/duration_minutes': 5.0, 'downtime/events/0/cause': 'Mantenimiento', 'sla_target': 99.95, 'alerts': 1, 'observations': 'Cumplió con el SLA con interrupciones mínimas.'}]\n"
     ]
    }
   ],
   "source": [
    "# Mostramos la carga de los datos de entrada\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f64751-09c0-4557-be88-76c562cdcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el contexto (system role)\n",
    "# Few-shot prompting en el context: Formato de salida con ejemplos para una respuesta estructurada\n",
    "context = \"\"\"Eres un analista de datos especializado en redactar informes narrativos detallados sobre la disponibilidad de servicios.\n",
    "Tus informes deben incluir:\n",
    "1. Un resumen del desempeño general.\n",
    "2. Un análisis detallado de cada servicio, incluyendo:\n",
    "   - Nombre\n",
    "   - Disponibilidad y objetivo del SLA\n",
    "   - Detalles del tiempo de inactividad (eventos, causas)\n",
    "   - Observaciones o recomendaciones.\n",
    "3. Una conclusión con recomendaciones accionables.\n",
    "El informe debe ser conciso y no superar los 500 tokens.\n",
    "\n",
    "Ejemplo:\n",
    "Informe de Disponibilidad: 2024-11-18 al 2024-11-24  \n",
    "\n",
    "Resumen:  \n",
    "- Todos los servicios cumplieron con los objetivos del SLA. Tiempo de inactividad total: 10 minutos en todos los servicios.  \n",
    "\n",
    "Análisis por Servicio:  \n",
    "1. Servicio A:  \n",
    "   - Disponibilidad: 99.95% (Objetivo: 99.90%)  \n",
    "   - Tiempo de inactividad: 5 minutos (1 evento: Mantenimiento el 2024-11-20).  \n",
    "   - Observaciones: SLA cumplido con interrupciones mínimas.  \n",
    "\n",
    "2. Servicio B:  \n",
    "   - Disponibilidad: 100% (Objetivo: 99.90%)  \n",
    "   - Tiempo de inactividad: Ninguno.  \n",
    "   - Observaciones: Rendimiento excelente.  \n",
    "\n",
    "Conclusión:  \n",
    "No se detectaron problemas graves. Continúe monitoreando para mantener el cumplimiento del SLA.  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "032ace93-15a4-42de-b986-c04ad8b289b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el prompt que vamos a utilizar, la petición (entrada) a la IA\n",
    "prompt = f\"\"\"\n",
    "Analiza los siguientes datos y genera un informe de disponibilidad estructurado en el formato especificado:\n",
    "{data_in}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54a1c1d-3b9a-4b76-8a98-e564b5254658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la estructura de la conversación\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": context},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc2b0436-c853-4bc5-88be-f0d04565cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la respuesta de la conversación y la almacenamos (raw) en response\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-4',\n",
    "    messages = conversation,\n",
    "    max_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a8c91d-5549-4716-889a-4496817a0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos solo la respuesta de la conversación\n",
    "narrated_summary = response[\"choices\"][0][\"message\"][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21da32cf-66c7-43ca-8085-78637ac6dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de Disponibilidad: 2024-11-27 al 2024-11-28  \n",
      "\n",
      "Resumen:  \n",
      "- Todos los servicios cumplieron con los objetivos del SLA. Tiempo de inactividad total: 20 minutos en todos los servicios.  \n",
      "\n",
      "Análisis por Servicio:  \n",
      "1. Servidor Web:  \n",
      "   - Disponibilidad: 99.87% (Objetivo: 99.90%)  \n",
      "   - Tiempo de inactividad: 15 minutos (1 evento: Fallo de red el 2024-11-27).  \n",
      "   - Observaciones: Cumplió con el SLA a pesar de una pequeña interrupción.  \n",
      "\n",
      "2. Servidor Backend:  \n",
      "   - Disponibilidad: 100% (Objetivo: 99.90%)  \n",
      "   - Tiempo de inactividad: Ninguno.  \n",
      "   - Observaciones: Rendimiento excelente.  \n",
      "\n",
      "3. Base de Datos:\n",
      "   - Disponibilidad: 99.95% (Objetivo: 99.95%)\n",
      "   - Tiempo de inactividad: 5 minutos (1 evento: Mantenimiento el 2024-11-28).\n",
      "   - Observaciones: Cumplió con el SLA con interrupciones mínimas.\n",
      "\n",
      "Conclusión:  \n",
      "A pesar de algún tiempo de inactividad, todos los servicios han conseguido cumplir con sus objetivos del SLA. Sin embargo, el \"Servidor Web\" necesita ser supervisado de cerca, debido al fallo de red observado.\n"
     ]
    }
   ],
   "source": [
    "# Desplegamos la respuesta por pantalla\n",
    "print(narrated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da8326f9-d127-4a40-bcd5-31d79a3d98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos nuevo prompt y lo agregamos a la conversación\n",
    "score_summary_request = \"En base al resumen narrado construído, se requiere calificar el desempeño de los servicios en general en relación al SLA objetivo, y se pide elegir una clasificación de entre 0 y 10, donde 0 es desastroso y 10 es la excelencia. Que número elegirías? Por favor, respondeme solo el número indicador, ni más ni menos.\"\n",
    "\n",
    "conversation.append({\"role\": \"user\", \"content\": score_summary_request})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58881db5-537e-4c2b-84b7-b4575aeb497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una nueva respuesta y la almacenamos en score_summary\n",
    "response_2 = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=conversation,\n",
    "    max_tokens=10\n",
    ")\n",
    "\n",
    "score_summary = response_2['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dbbc329-9972-45f1-957b-1459f1e0db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 8\n"
     ]
    }
   ],
   "source": [
    "# Desplegamos por pantalla el score obtenido\n",
    "print(\"Score:\", score_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b9995ca-f066-44d5-9bfa-b0bdd255f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos nuevo prompt, esta vez para la creación de una imagen a partir de texto y lo añadimos a la conversación\n",
    "score_image = f\"Crear un diseño minimalista estilo gauge que refleje un desempeño basado en un score. El diseño es de un color entre rojo (score 0) y verde (score 10), con tonos intermedios según el score. Fondo blanco, diseño limpio y profesional. La imagén resultante no debe de tener números ni letras. El score es {score_summary}\"\n",
    "\n",
    "conversation.append({\"role\": \"user\", \"content\": score_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91a892e6-a685-4b34-a824-b7e481466811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-zxk0LPtO3ZaaLczq31fRsE41/user-bLzPwqfphC1UZxdNXxq563OB/img-uptebrq5OZx2KCFZVQ756XH5.png?st=2024-12-20T21%3A17%3A36Z&se=2024-12-20T23%3A17%3A36Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-20T20%3A23%3A35Z&ske=2024-12-21T20%3A23%3A35Z&sks=b&skv=2024-08-04&sig=dXmaswDAq6r78ZXWERvroEu%2Bzn4KnYz8PAdO3WwEmi0%3D\n"
     ]
    }
   ],
   "source": [
    "# Generamos la imagen de respuesta y desplegamos el enlace para acceder a ella\n",
    "image_response = openai.Image.create(\n",
    "    prompt=score_image,\n",
    "    n=1,\n",
    "    size=\"256x256\"\n",
    ")\n",
    "\n",
    "print(image_response['data'][0]['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2b97d-4465-4cbd-90f0-35279459fecc",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "La implementación del proyecto ha logrado cumplir con los objetivos planteados inicialmente. \n",
    "Los principales resultados obtenidos incluyen:\n",
    "\n",
    "**Interacción con OpenAI:**\n",
    "\n",
    "La integración con OpenAI se realizó con éxito, permitiendo generar informes narrativos estructurados basados en datos de entrada. Los resultados de las interacciones son precisos y cumplen con los requisitos del formato especificado tanto para la entrada/lectura de datos, como para la salida. Lo que no se logró tanto fue la generación de imagenes a partir de texto usando la api de openai. Creemos que los prompts están bien trabajados y son buenos, pero la versión de openai que estamos utilizando es bastante antigua y en este caso resultó ser una limitante. Creemos que el mismo prompt para generación de imágenes pero a través de una tecnología más reciente, nos puede generar muy buenos resultados.\n",
    "\n",
    "\n",
    "**Generación de imágenes:**\n",
    "\n",
    "En nuestra solución, la generación de imagenes a partir de texto no era un punto tan valioso, de todas maneras se incluyó en la solución para demostrar el conocimiento adquirido en el curso. En el repositorio de github incluímos la imagen guage_txt_to_img_noapi.jpg generada a través de la interfaz web de Nightcafe. Dicha imágen fue generada con el mismo prompt que se utilizó en el código utilizando dalle a través de openai 0.28.\n",
    "\n",
    "Prompt utilizado:\n",
    "Crear un diseño minimalista estilo gauge que refleje un desempeño basado en un score. El diseño es de un color entre rojo (score 0) y verde (score 10), con tonos intermedios según el score. Fondo blanco, diseño limpio y profesional. La imagén resultante no debe de tener números ni letras. El score es 8\n",
    "\n",
    "\n",
    "**Soporte para múltiples formatos de entrada:**\n",
    "\n",
    "Se implementaron funciones que permiten cargar datos desde archivos JSON, CSV y Excel, lo que otorga flexibilidad al sistema para manejar distintos tipos de datos de entrada.\n",
    "\n",
    "\n",
    "\n",
    "**Gestión segura de credenciales:**\n",
    "\n",
    "Se implementó el uso de variables de entorno para manejar la API key de OpenAI, lo que refuerza la seguridad y asegura que las credenciales confidenciales no estén expuestas en el código fuente.\n",
    "\n",
    "\n",
    "**Documentación y legibilidad:**\n",
    "\n",
    "El código se estructuró en funciones independientes, en la medida que fue posible, sin perder de vista la simplicidad del seguimiento que te da la jupyter notebook.\n",
    "Se comentaron las lineas de código relevantes y se documentaron las funciones, lo que facilita su comprensión, mantenimiento y escalabilidad. Cada función está documentada adecuadamente y sigue las buenas prácticas de programación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c5931-df1e-4b76-8076-de48aa8628ab",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "Al finalizar el desarrollo del proyecto, se pueden destacar las siguientes conclusiones:\n",
    "\n",
    "**Objetivos alcanzados:**\n",
    "\n",
    "El proyecto logró los objetivos propuestos, proporcionando un sistema funcional y flexible para analizar datos y generar informes detallados, narrativos y visuales, siendo esta solución, el componente o módulo que trabaja con IA para enriquecer una solución ya creada y funcional.\n",
    "\n",
    "\n",
    "**Flexibilidad y escalabilidad:**\n",
    "Este desarrollo no pretende ser el software que recolecta los datos, los trabaja con la IA y los publica en un documento unificado, sino por el contrario, lee los datos de un reporte ya establecido y retorna la salida narrada en texto plano de forma simple y escalable. Luego, esta salida la pueden tomar otros modulos que se encargan de formatear la salida acorde al formato del documento a presentar, ya sea presentación, pdf o excel.\n",
    "El sistema está preparado para ser ampliado en el futuro. Por ejemplo, se podrían agregar nuevos formatos de entrada o extender la funcionalidad para generar informes personalizados.\n",
    "\n",
    "\n",
    "**Impacto de la automatización:**\n",
    "La integración con OpenAI demostró ser una herramienta poderosa para automatizar tareas complejas, como la generación de informes narrativos detallados. Esto puede ser especialmente útil en entornos empresariales donde la generación de informes es una tarea frecuente.\n",
    "\n",
    "\n",
    "**Viabilidad y costos:**\n",
    "A lo largo del desarrollo del proyecto, uno de los objetivos fue mantener los costos asociados al uso de la API de OpenAI bajo control. Para lograrlo, se implementaron estrategias como la reducción de los prompts enviados y la selección cuidadosa de los modelos de IA a utilizar. Siempre se optó por modelos más económicos cuando la complejidad de la tarea lo permitía, logrando resultados satisfactorios sin comprometer el presupuesto.\n",
    "\n",
    "Sin embargo, en situaciones donde se requería mayor precisión y profundidad en las respuestas, como en la generación del resumen narrativo de los datos, se decidió invertir en modelos más avanzados. Esta decisión se tomó con la premisa de garantizar que los resultados fueran consistentes y valiosos, priorizando la calidad por encima del ahorro en esos casos puntuales.\n",
    "\n",
    "Además, se aseguró que el sistema fuera eficiente en términos de consumo: cada informe requiere un número reducido de consultas a la API, lo que minimiza significativamente el costo operativo por reporte. Para evitar escenarios imprevistos que pudieran aumentar los costos, se definieron límites claros de tokens en cada llamado a la API, protegiendo el proyecto de posibles errores o \"catástrofes\" en el consumo de recursos.\n",
    "\n",
    "En resumen, el enfoque adoptado logró un balance entre costos controlados y resultados de calidad, demostrando que es posible implementar soluciones basadas en IA de manera eficiente y rentable.\n",
    "\n",
    "\n",
    "\n",
    "En resumen, el proyecto no solo cumplió con los objetivos establecidos, sino que también demostró ser una solución robusta, rentable y adaptable a distintos escenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee037c3-d216-43e1-bd82-ce0a77bed0c6",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "**OpenAI API Documentation:**\n",
    "https://platform.openai.com/docs\n",
    "\n",
    "**Pandas Library Documentation:**\n",
    "https://pandas.pydata.org/docs/\n",
    "\n",
    "**Python dotenv Library Documentation:**\n",
    "https://pypi.org/project/python-dotenv/\n",
    "\n",
    "**Curso de Coderhouse: Inteligencia artificial: Generación de Prompts, Comisión #67115**\n",
    "\n",
    "**Artículos y recursos propios sobre programación y buenas prácticas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87750c3c-cc3a-44d3-8116-407c40a3c8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
